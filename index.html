<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ivona Najdenkoska</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üë©üèº‚Äçüíª</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name><b><span class="heading_color">Ivona</span></b> Najdenkoska</name>
              </p>
              <p>I'm a PhD student at the <a href="https://uva.nl">University of Amsterdam</a>, supervised by <a href="https://staff.fnwi.uva.nl/m.worring/">Marcel Worring</a>. I work on vision and language learning at the Informatics Institute, where I'm part of <a href="https://multix.io/">MultiX Amsterdam</a> and <a href="https://ivi.fnwi.uva.nl/aimlab/">AIMLab</a> groups.
              </p>
              <p>Starting from June 2023, I'm a Research Scientist Intern at <a href="https://ai.facebook.com/">Meta AI</a>, working on text-to-image generation and diffusion models within the Generative AI team.</p>
              <p>
                I obtained my master degree in Artificial Inteligence at the KU Leuven. Before that, I spent some time as a Software Engineer in Netcetera and I was an undergraduate student in Computer Science and Engineering at the FCSE at University ‚ÄùSs. Cyril and Methodius‚Äù in Skopje.
              </p>
              <p style="text-align:center">
                <a href="mailto:i.najdenkoska@uva.nl">Email</a> &nbsp/&nbsp
                <a href="https://twitter.com/ivonajdenkoska">Twitter</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=2rFidrcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ivonajdenkoska/">Github</a>  &nbsp/&nbsp
                <a href="https://linkedin.com/in/ivona-najdenkoska/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/ivona_photo_2.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ivona_photo_2.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading><span class="heading_color">News</span></heading>
              <ul>
                <li>[June 2023] I started a new position as a Research Scientist Intern at <a href="https://ai.facebook.com/">Meta AI</a> in Menlo Park, California üá∫üá∏</li>
                <li>[Mar 2023] I will be a TA for <a href="https://uvadl2c.github.io/">Deep Learning 2</a>,  Vison-Language learning module.</li>
                <li>[Jan 2023] Our paper on multimodal few-shot learning is accepted to ICLR 2023 üéâ</li>
                <li>[Dec 2022] I presented my work in the 6th Workshop on Meta-Learning at NeurIPS 2022</li>
                <li>[Nov 2022] I taught a guest lecture on Attention & Transformers, as part of the <a href="http://uvadlc.github.io/">Deep Learning 1</a> course at UvA</li>
                <li>[Sept 2022] Our paper is runner-up for the <a href="https://www.sciencedirect.com/journal/medical-image-analysis/about/news">MEDIA Best Paper Award </a> at MICCAI 2022</li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading><span class="heading_color">Research</span></heading>
              <p>
                My research is at the intersection of vision and language learning, with a particular focus on multimodal few-shot learning. 
                I'm interested in better understanding what large-scale vision and language models learn, and how to exploit that through in-context learning and prompting. 
                Some of my work also includes automated linguistic interpretation of images, as well as its applications in the medical domain.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/metavl_model.png' width="200">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Meta Learning To Bridge Vision and Language Models for Multimodal Few-Shot Learning</papertitle>
              <br>
              <strong>Ivona Najdenkoska</strong>,
              <a href="https://scholar.google.ca/citations?user=DnBb3e0AAAAJ&hl=en">Xiantong Zhen</a>,
              <a href="https://staff.fnwi.uva.nl/m.worring/">Marcel Worring</a>
              <br>
              <em>In ICLR</em> 2023 &nbsp 
              <br>
              <a href="https://arxiv.org/pdf/2302.14794.pdf">paper</a> | 
              <a href="https://github.com/ivonajdenkoska/multimodal-meta-learn">code</a>
        
              <p></p>
              <p>We propose a method for bridging large-scale vision and language models to perform multimodal few-shot learning. The model meta-learns visual prefixes from frozen visual backbone, which are used as prompts to a large langauge model.</p>
            </td>
          </tr> 

          <tr>
            <td style="padding:0px;width:0%;vertical-align:middle">
              <div class="one">
                <img src='images/med_vqa_model.png' width="200">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Open-Ended Medical Visual Question Answering Through Prefix Tuning of Language Models</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=ovqQIMUAAAAJ&hl=en">Tom van Sonsbeek</a>, <a href="https://mmderakhshani.github.io/">Mohammad M. Derakshani</a>, <strong>Ivona Najdenkoska</strong>, <a href="https://www.ceessnoek.info/">Cees Snoek</a>,
              <a href="https://staff.fnwi.uva.nl/m.worring/">Marcel Worring</a>
              <br>
              <em>In arXiv</em> 2023 &nbsp 
              <br>
              <a href="https://arxiv.org/pdf/2303.05977.pdf">paper</a> 
              <!-- <a href="">code</a> -->
        
              <p></p>
              <p>We introduce a novel method for open-ended VQA particularly suited for small, domain-specific, medical datasets. We employ parameter-efficient strategies for efficient tuning of the LMs. </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/meta_setting.png' width="200">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Meta-Learning Makes a Better Multimodal Few-Shot Learner</papertitle>
              <br>
              <strong>Ivona Najdenkoska</strong>,
              <a href="https://scholar.google.ca/citations?user=DnBb3e0AAAAJ&hl=en">Xiantong Zhen</a>,
              <a href="https://staff.fnwi.uva.nl/m.worring/">Marcel Worring</a>
              <br>
              <em>In 6th Workshop on Meta-Learning at NeurIPS</em> 2022 &nbsp 
              <br>
              <a href="https://openreview.net/pdf?id=7HPmTa_FdY">paper</a>
        
              <p></p>
              <p>We define a meta-learning approach for multimodal few-shot learning, to leverage its strong ability of accruing knowledge across tasks (predecessor of the ICLR 2023 work).</p>
            </td>
          </tr> 

          <tr>
            <td style="padding-left:20px;padding-bottom:30px;width:25%;vertical-align:middle>
              <div class="one">
                <img src='images/media_model.jpg' width="125", height="170">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Uncertainty-aware Report Generation for Chest X-rays by Variational Topic Inference</papertitle>
              <br>
              <strong>Ivona Najdenkoska</strong>,
              <a href="https://scholar.google.ca/citations?user=DnBb3e0AAAAJ&hl=en">Xiantong Zhen</a>,
              <a href="https://staff.fnwi.uva.nl/m.worring/">Marcel Worring</a>, <a href="https://ling-shao.github.io/">Ling Shao</a>
              <br>
              <em>In Medical Image Analysis</em> 2022, <a href="https://www.sciencedirect.com/journal/medical-image-analysis/about/news" style="color: red">Best Paper Honorable Mention</a>
              <br>
              <a href="https://www.sciencedirect.com/science/article/pii/S1361841522002341">paper</a> | 
              <a href="https://github.com/ivonajdenkoska/variational-xray-report-gen">code</a> 
              <p></p>
              <p>We present a probabilistic latent variable model for chest X-Ray report generation. We extend the VTI model by providing a fully Transformer-based definition and explore the trade-off between an LSTM- or Transformer-based decoder for generation of medical text. </p> </br></br>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/lifelonger_model.png' width="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">              
                <papertitle>LifeLonger: A Benchmark for Continual Disease Classification</papertitle>
              <br>
              <a href="https://mmderakhshani.github.io/">Mohammad M. Derakshani</a>, <strong>Ivona Najdenkoska</strong>, 
              <a href="https://scholar.google.com/citations?user=ovqQIMUAAAAJ&hl=en">Tom van Sonsbeek</a>,
              <a href="https://scholar.google.ca/citations?user=DnBb3e0AAAAJ&hl=en">Xiantong Zhen</a>, 
              <a href="https://sites.google.com/site/dwarikanathmahapatra/">Dwarikanath Mahapatra</a>,
              <a href="https://staff.fnwi.uva.nl/m.worring/">Marcel Worring</a>, <a href="https://www.ceessnoek.info/">Cees Snoek</a> 
              <br>
              <em>In MICCAI</em> 2022
              <br>
              <a href="https://arxiv.org/pdf/2204.05737.pdf">paper</a> |
              <a href="https://github.com/mmderakhshani/LifeLonger">code</a> |
              <a href="https://lifelonger.github.io/">project page</a>
              <p></p>
              <p>We introduce LifeLonger, a benchmark for continual disease classification on the MedMNIST collection, by applying existing state-of-the-art continual learning methods.</p> </br></br>
            </td>
          </tr> 

          <tr>
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/midl_model.png' width="200">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Learning to Automatically Generate Accurate ECG Captions</papertitle>
              <br>
              Mathieu G. G. Bartels, <strong>Ivona Najdenkoska</strong>, Rutger van de Leur, Arjan Sammani, Karim Taha, David M. Knigge, Pieter Doevendans, <a href="https://staff.fnwi.uva.nl/m.worring/">Marcel Worring</a>, Rene van Es.
              <br>
            <em>In MIDL</em> 2022
              <br>
              <a href="https://openreview.net/pdf?id=Y-kXbPYtzsg">paper</a> 
              <p></p>
              <p>We introduce a label-guided Transformer model, and show that it is possible to automatically generate relevant and readable ECG descriptions with a data-driven captioning model. </p> </br></br>
            </td>
          </tr> 

          <tr>
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/vti_model.png' width="200">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Variational Topic Inference for Chest X-Ray Report Generation</papertitle>
              <br>
              <strong>Ivona Najdenkoska</strong>, 
              <a href="https://scholar.google.ca/citations?user=DnBb3e0AAAAJ&hl=en">Xiantong Zhen</a>,
              <a href="https://staff.fnwi.uva.nl/m.worring/">Marcel Worring</a>, <a href="https://ling-shao.github.io/">Ling Shao</a>
              <br>
            <em>In MICCAI</em> 2021, <span style="color: red">Oral + Travel Award</span>
              <br>
              <a href="https://arxiv.org/pdf/2107.07314.pdf">paper</a> |
              <a href="https://github.com/ivonajdenkoska/variational-xray-report-gen">code</a> 
              <p></p>
              <p>We propose Variational Topic Inference (VTI), a probabilistic latent variable model for automatic report generation. We introduce a set of topics as latent variables to guide sentence generation by aligning image and language modalities in the latent space. </p> </br></br>
            </td>
          </tr> 
          
        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading class="heading_color">Academic experience</heading>
            </td>
            <td width="95%" valign="middle">
              <dl>
                <dt><a href="https://uva.nl">University of Amsterdam</a> | Teaching Assistant in <a href="https://www.uva.nl/shared-content/programmas/en/masters/artificial-intelligence/artificial-intelligence.html">Master of AI</a> | Feb 2021 - present
                  <dl>
                     <dt>- <a href="http://uvadlc.github.io/">Deep Learning 1 (2021, 2022)</a>; Multimedia Analytics (2022); Information Visualization (2021).</dt>
                     <dt>- Guest lecturer for Deep Learning 1 (2021, 2022)</dt>
                     <dt>- Supervision of Master in AI students during their thesis projects. 
                   </dt>
                   </dl>
                </dt>                
              </dl>
                              
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading class="heading_color">Work experience</heading>
            </td>
            <td width="95%" valign="middle">
              <dl>
                <dt> <a href="https://www.netcetera.com/home.html">Netcetera</a> | Software Engineer | Sept 2017 - Sept 2018
                </dt>
                <dt> <a href="https://www.netcetera.com/home.html">Netcetera</a> | Software Engineering Intern | Apr 2017 - Jul 2017
                </dt>
                <dt> <a href="https://www.haselt.com/">Haselt</a> | Software Engineering Intern | Jun 2016 - Sept 2016 
                </dt>
                            
              </dl>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading class="heading_color">Misc</heading>
            </td>
            <td width="85%" valign="middle">
              <ul>
                 <li>Reviewer for: CVPR, ICLR, ICMR, Computer Vision & Image Understanding Journal, IEEE Transactions on Medical Imaging, Journal of Biomedical and Health Informatics.</li>    
                 <li>Invited talk @ Amsterdam Medical Data Science (AMDS) meetup | July 2022, Amsterdam.</li>   
                 <li>Participant @ DeepLearn Summer School, organized by IRDTA, | July 2022, Gran Canaria.</li>
                 <li>Participant @ Oxford Machine Learning Summer School, organized by AI for Global Goals | August 2021, Oxford - virtual.</li>
              </ul>
                              
            </td>
          </tr>
        </tbody></table>


      </td>
    </tr>
  </table>
  <div align="right"><small> Website template <a href="https://jonbarron.info/">here</a>. </small> </div>

</body>

</html>
